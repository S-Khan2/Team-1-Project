AWSTemplateFormatVersion: 2010-09-09
Description: >-
  Template to deploy a lambda which is triggered by an S3 event.
Parameters:
 DeploymentBucket:
  Type: String
  Description: This is the place where the zip and templates are stored
 DeploymentPackageKey:
  Type: String
  Description: Name of the zip file
 NotificationBucket:
  Type: String
  Description: S3 bucket  used for the Lambda event notification
Resources:
  LambdaIAMRole:
    Type: 'AWS::IAM::Role'
    DeletionPolicy : Retain
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Policies:
        - PolicyName: LambdaLogsPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 's3:GetBucketNotification'
                  - 's3:PutBucketNotification'
                Resource: !Sub 'arn:aws:s3:::${NotificationBucket}'
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: '*'
  T1LambdaFunction:
    Type: 'AWS::Lambda::Function'
    DeletionPolicy : Retain
    Properties:
      Code:
        ZipFile: |
          # TODO: Package all dependencies: cryptography, 
          import pandas as pd
          import urllib.parse
          import boto3
          import logging
          import sqlalchemy
          import os
          from extractcsv import read_csvfile_into_dataframe
          #from test_table import create_sales_tables
          from load import *
          #from transform_3nf import *
          #from suppress_pii import encrypt_pii,decrypt_pii
          from transform_3nf import third_normal_form
          import suppress_pii as pii

          from create_db import *

          TRANSACTIONS_TABLE = "transactions"
          PRODUCTS_TABLE = "products"
          BASKET_ITEMS_TABLE = "basket_items"

          s3 = boto3.client('s3')

          # s3_r = boto3.resource('s3')

          LOGGER = logging.getLogger()
          LOGGER.setLevel(logging.INFO)
          def handler(event, context):
              LOGGER.info(f'Event structure: {event}')
              #Get the object from the event 
              #for i in event['Records']['s3']['bucket']['name']:
              #print(event)
              bucket = event['Records'][0]['s3']['bucket']['name']
              key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')
              print(f"KEY = {key}")
              file_name =  '/tmp/' + key.split("/")[-1]
              s3 = boto3.client('s3')
              s3.download_file(bucket, key, file_name)
              #lst = os.listdir()
              #print(lst)
              
              #Extract the csv
              data_df = read_csvfile_into_dataframe(file_name)
              #print(df)
              #Drop the card number column from the dataframe
              
              
              pii.drop_column(data_df, "card_number")
              # secretkey = pii.load_key()
              # pii.encrypt_pii(data_df, "customer_name")
              # 3. Generate UUID for transactions, then efficently represent the cleaned data
              table_dict = third_normal_form(data_df)     # TODO: In line 92, add UUID
              # print(table_dict[TRANSACTIONS_TABLE])
              # print(table_dict[PRODUCTS_TABLE])
              # print(table_dict[BASKET_ITEMS_TABLE])
              
              # SQS
              
              #LOAD
              
              # Connect to Redshift using Psycopg2
              (conn, cursor) = connect_db()
              create_tables(conn, cursor)
              load_mvp_tables(conn, cursor, table_dict)
              save_and_close_connection(conn, cursor)
      Handler: index.handler
      FunctionName: T1LambdaFunction
      Layers: 
       - arn:aws:lambda:eu-west-1:506555054152:layer:Team1-Dependencies-1:1
       - arn:aws:lambda:eu-west-1:506555054152:layer:psycopg2:8
      Role: !GetAtt LambdaIAMRole.Arn
      Runtime: python3.9
      Timeout: 30
  LambdaInvokePermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      FunctionName: !GetAtt T1LambdaFunction.Arn
      Action: 'lambda:InvokeFunction'
      Principal: s3.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !Sub 'arn:aws:s3:::${NotificationBucket}'
  LambdaFunction:
    Type: 'AWS::Lambda::Function'
    DeletionPolicy : Retain
    Properties:
      Handler: index.lambda_handler
      Role: !GetAtt LambdaIAMRole.Arn
      Code:
        S3Bucket: !Ref DeploymentBucket
        S3Key: !Ref DeploymentPackageKey
      Runtime: python3.9
      Timeout: 50
  S3BucketPermission:
   Type: AWS::Lambda::Permission
   Properties:
    Action: lambda:InvokeFunction
    FunctionName: !Ref T1LambdaFunction
    Principal: s3.amazonaws.com
    SourceArn: !GetAtt S3Bucket.Arn
  S3Bucket:
    Type: AWS::S3::Bucket
    DeletionPolicy : Retain
    Properties: 
      BucketName: delon6-team1-raw-data
      NotificationConfiguration:
        LambdaConfigurations:
              - Event: s3:ObjectCreated:*
                Function: !GetAtt LambdaFunction.Arn